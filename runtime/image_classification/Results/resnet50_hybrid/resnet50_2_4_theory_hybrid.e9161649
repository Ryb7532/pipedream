Traceback (most recent call last):
  File "main_with_runtime.py", line 623, in <module>
Traceback (most recent call last):
  File "main_with_runtime.py", line 623, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "main_with_runtime.py", line 623, in <module>
  File "main_with_runtime.py", line 623, in <module>
    main()
    main()
  File "main_with_runtime.py", line 330, in main
  File "main_with_runtime.py", line 330, in main
    main()
  File "main_with_runtime.py", line 330, in main
    main()
  File "main_with_runtime.py", line 330, in main
    train(train_loader, r, optimizer, epoch)
  File "main_with_runtime.py", line 388, in train
    train(train_loader, r, optimizer, epoch)
  File "main_with_runtime.py", line 388, in train
    train(train_loader, r, optimizer, epoch)
  File "main_with_runtime.py", line 388, in train
    train(train_loader, r, optimizer, epoch)
  File "main_with_runtime.py", line 388, in train
    r.run_forward()
  File "../runtime.py", line 510, in run_forward
    r.run_forward()
  File "../runtime.py", line 510, in run_forward
    r.run_forward()
    r.run_forward()
  File "../runtime.py", line 510, in run_forward
  File "../runtime.py", line 510, in run_forward
    self._run_forward(tensors)
    self._run_forward(tensors)
  File "../runtime.py", line 558, in _run_forward
  File "../runtime.py", line 558, in _run_forward
    self._run_forward(tensors)
    self._run_forward(tensors)
  File "../runtime.py", line 558, in _run_forward
  File "../runtime.py", line 558, in _run_forward
    for input_name in input_names])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    for input_name in input_names])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    for input_name in input_names])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    for input_name in input_names])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    result = self.forward(*input, **kwargs)
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 368, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 368, in forward
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 368, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 368, in forward
    return self.module(*inputs[0], **kwargs[0])
    return self.module(*inputs[0], **kwargs[0])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    return self.module(*inputs[0], **kwargs[0])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    return self.module(*inputs[0], **kwargs[0])
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/pipedream/runtime/image_classification/models/resnet50/gpus=2_4_theory/stage0.py", line 107, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/pipedream/runtime/image_classification/models/resnet50/gpus=2_4_theory/stage0.py", line 115, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/pipedream/runtime/image_classification/models/resnet50/gpus=2_4_theory/stage0.py", line 115, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/pipedream/runtime/image_classification/models/resnet50/gpus=2_4_theory/stage0.py", line 115, in forward
    out34 = self.layer34(out33)
    out25 = out25 + out17
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    out34 = self.layer34(out33)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 2; 15.90 GiB total capacity; 14.91 GiB already allocated; 3.38 MiB free; 317.18 MiB cached)
    out34 = self.layer34(out33)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 507, in __call__
    result = self.forward(*input, **kwargs)
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    result = self.forward(*input, **kwargs)
  File "/home/6/17B13541/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 3; 15.90 GiB total capacity; 15.02 GiB already allocated; 3.38 MiB free; 236.18 MiB cached)
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 1; 15.90 GiB total capacity; 15.02 GiB already allocated; 3.38 MiB free; 236.18 MiB cached)
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 15.90 GiB total capacity; 15.02 GiB already allocated; 19.38 MiB free; 236.18 MiB cached)
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.90 GiB total capacity; 15.04 GiB already allocated; 19.38 MiB free; 211.68 MiB cached)

Exception in thread Thread-2:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 1; 15.90 GiB total capacity; 15.03 GiB already allocated; 3.38 MiB free; 223.93 MiB cached)

Exception in thread Thread-2:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 2; 15.90 GiB total capacity; 14.93 GiB already allocated; 3.38 MiB free; 291.68 MiB cached)

Exception in thread Thread-2:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 3; 15.90 GiB total capacity; 15.04 GiB already allocated; 3.38 MiB free; 211.68 MiB cached)

Exception in thread Thread-4:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 15.90 GiB total capacity; 15.05 GiB already allocated; 5.38 MiB free; 213.43 MiB cached)

Exception in thread Thread-4:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 1; 15.90 GiB total capacity; 15.05 GiB already allocated; 3.38 MiB free; 213.43 MiB cached)

Exception in thread Thread-4:
Traceback (most recent call last):
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/apps/t3/sles12sp4/free/python/3.6.5/gcc4.8.5/lib/python3.6/threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "../communication.py", line 488, in recv_helper_thread
    sub_process_group=sub_process_group)
  File "../communication.py", line 541, in _recv
    tensor = torch.zeros(received_tensor_shape, dtype=dtype).cuda()
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 3; 15.90 GiB total capacity; 15.05 GiB already allocated; 3.38 MiB free; 213.43 MiB cached)

